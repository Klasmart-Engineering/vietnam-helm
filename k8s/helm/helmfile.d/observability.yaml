repositories:
  - name: bitnami
    url: https://charts.bitnami.com/bitnami

  - name: fluent
    url: https://fluent.github.io/helm-charts

  - name: prometheus
    url: https://prometheus-community.github.io/helm-charts

  - name: grafana
    url: https://grafana.github.io/helm-charts

  - name: oauth2-proxy
    url: https://oauth2-proxy.github.io/manifests

environments:
  vietnam-alpha:
    values:
      - ../../../env/vietnam-alpha/.env.yaml
  vietnam-beta:
    values:
      - ../../../env/vietnam-beta/.env.yaml
  vietnam-production:
    values:
      - ../../../env/vietnam-production/.env.yaml      
  indonesia-staging:
    values:
      - ../../../env/indonesia-staging/.env.yaml
  indonesia-production:
    values:
      - ../../../env/indonesia-production/.env.yaml
  indonesia-rk-prod:
    values:
      - ../../../env/indonesia-rk-prod/.env.yaml
  indonesia-rk-beta:
    values:
      - ../../../env/indonesia-rk-beta/.env.yaml

releases:
  - name: monitoring
    namespace: monitoring
    chart: ../charts/kube-monitoring
    version: ~0.1.0
    condition: helm_kube_monitoring.enabled
    values:  
      # https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml
      - kube-prometheus-stack:
          enabled: {{ .Values.helm_prometheus.enabled }}
          alertmanager:
            config:
              global:
                # This is the webhook URL to our own kidsloop slack app
                slack_api_url: 'https://hooks.slack.com/services/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'
            alertmanagerSpec:
              routePrefix: /alertmanager/
              externalUrl: https://mon{{ .Values.kl_domain }}/alertmanager/
            templateFiles:
              # This file is a simple template to pass helm variables through to the alertmanager instance
              kidsloop.helm.tmpl: |-
                {{`{{ define "slack.kidsloop.channel" }}`}}{{ .Values.kube_monitoring.slack_channel }}{{`{{ end }}`}}

            ingress:
              enabled: true
              ingressClassName: nginx
              annotations:
                cert-manager.io/cluster-issuer: "letsencrypt"
                # https://kubernetes.github.io/ingress-nginx/examples/auth/basic/

                # Basic auth creds
                # nginx.ingress.kubernetes.io/auth-type: basic
                # # name of the secret that contains the user/password definitions
                # nginx.ingress.kubernetes.io/auth-secret: basic-auth
                # # message to display with an appropriate context why the authentication is required
                # nginx.ingress.kubernetes.io/auth-realm: 'mon{{ .Values.kl_domain }}'

                # OAuth config (mutually exclusive with basic auth)
                nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
                nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
                # Other stuff for GKE LB
                kubernetes.io/ingress.allow-http: 'false'
                kubernetes.io/ingress.class: nginx
                kubernetes.io/ingress.global-static-ip-name: ingress-https-load-balancer
              labels: {}
              hosts:
                - mon{{ .Values.kl_domain }}
              paths:
                - /alertmanager/
              tls:
                - hosts:
                    - mon{{ .Values.kl_domain }}
                  secretName: mon-cert
          prometheus:
            prometheusSpec:
              externalUrl: https://mon{{ .Values.kl_domain }}/
              # externalUrl: https://mon{{ .Values.kl_domain }}/
              storageSpec:
                volumeClaimTemplate:
                  spec:
                    storageClassName: standard
                    accessModes: ["ReadWriteOnce"]
                    resources:
                      requests:
                        storage: 10Gi
            ingress:
              enabled: true
              ingressClassName: nginx
              annotations:
                cert-manager.io/cluster-issuer: "letsencrypt"
                # https://kubernetes.github.io/ingress-nginx/examples/auth/basic/
                # type of authentication
                # nginx.ingress.kubernetes.io/auth-type: basic
                # # name of the secret that contains the user/password definitions
                # nginx.ingress.kubernetes.io/auth-secret: basic-auth
                # # message to display with an appropriate context why the authentication is required
                # nginx.ingress.kubernetes.io/auth-realm: 'mon{{ .Values.kl_domain }}'
                # These are the OAuth params
                nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
                nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
                # Other stuff for GKE LB
                kubernetes.io/ingress.allow-http: 'false'
                kubernetes.io/ingress.class: nginx
                kubernetes.io/ingress.global-static-ip-name: ingress-https-load-balancer
              labels: {}
              hosts:
                - mon{{ .Values.kl_domain }}
              paths:
                - /
              tls:
                - hosts:
                    - mon{{ .Values.kl_domain }}
                  secretName: mon-cert
          grafana:
            # https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
            additionalDataSources:
              - name: Loki
                url: http://monitoring-loki.monitoring.svc.cluster.local:3100
                orgId: 1
                type: loki
              - name: Redis
                url: redis://{{ .Values.redis_host }}:6379
                orgId: 1
                type: redis-datasource

            plugins:
              - redis-datasource

            ingress:
              enabled: true
              # ingressClassName: nginx
              annotations:
                cert-manager.io/cluster-issuer: "letsencrypt"
                # https://kubernetes.github.io/ingress-nginx/examples/auth/basic/
                # type of authentication
                # nginx.ingress.kubernetes.io/auth-type: basic
                # # name of the secret that contains the user/password definitions
                # nginx.ingress.kubernetes.io/auth-secret: basic-auth
                # # message to display with an appropriate context why the authentication is required
                # nginx.ingress.kubernetes.io/auth-realm: 'mon{{ .Values.kl_domain }}'
                # These are the OAuth params
                nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
                nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
                # Other stuff for GKE LB
                kubernetes.io/ingress.allow-http: 'false'
                kubernetes.io/ingress.class: nginx
                kubernetes.io/ingress.global-static-ip-name: ingress-https-load-balancer
              labels: {}
              hosts:
                - mon{{ .Values.kl_domain }}
              path: /grafana/
              pathType: ImplementationSpecific
              paths:
                - /grafana/
              tls:
                - hosts:
                    - mon{{ .Values.kl_domain }}
                  secretName: mon-cert
            grafana.ini:
              server:
                domain: mon{{ .Values.kl_domain }}
                root_url: "https://%(domain)s/grafana"
                serve_from_sub_path: true
                enable_gzip: true
              users:
                auto_assign_org_role: Admin
              auth:
                oauth_auto_login: true
              auth.basic:
                enabled: false
              auth.generic_oauth:
                enabled: true
                client_id: ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/grafana_client_id
                client_secret: ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/grafana_client_secret
                scopes: openid email profile
                empty_scopes: false
                auth_url: https://dex.devops.klpsre.com/auth
                token_url: https://dex.devops.klpsre.com/token
                api_url: https://dex.devops.klpsre.com/userinfo
                allowed_domains: calmid.com kidsloop.live kidsloopglobal.onmicrosoft.com
                allow_sign_up: true
                tls_skip_verify_insecure: false
        oauth2-proxy:
          enabled: {{ .Values.helm_prometheus.enabled }}
          # Oauth client configuration specifics
          config:
            # These are helmfile secrets (vals), see here on usage:
            # https://github.com/variantdev/vals#suported-backends
            # OAuth client ID
            clientID: ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/client_id
            # OAuth client secret
            clientSecret: ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/client_secret
            # Cookie encryption secret
            cookieSecret: ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/cookie_secret
            # Create a new secret with the following command
            # openssl rand -base64 32 | head -c 32 | base64
            # Use an existing secret for OAuth2 credentials (see secret.yaml for required fields)
            # Example:
            # existingSecret: secret
            # The name of the cookie that oauth2-proxy will create
            # If left empty, it will default to the release name
            cookieName: "ref+vault://{{ .Values.vault_path }}/monitoring/sso?address={{ .Values.vault_addr }}#/client_id"
            configFile: |-
              # email_domains = [ "*" ]
              upstreams = [ "file:///dev/null" ]
              http_address="0.0.0.0:4180"
              provider="oidc"
              email_domains = [ "calmid.com", "kidsloop.live", "kidsloopglobal.onmicrosoft.com" ]
              oidc_issuer_url="https://dex.devops.klpsre.com"
              cookie_secure="true"

          ingress:
            enabled: true
            path: /oauth2
            # Only used if API capabilities (networking.k8s.io/v1) allow it
            pathType: ImplementationSpecific
            # Used to create an Ingress record.
            hosts:
              - mon{{ .Values.kl_domain }}
            annotations:
              cert-manager.io/cluster-issuer: "letsencrypt"
              # Other stuff for GKE LB
              kubernetes.io/ingress.allow-http: 'false'
              kubernetes.io/ingress.class: nginx
              kubernetes.io/ingress.global-static-ip-name: ingress-https-load-balancer
            tls:
              # Secrets must be manually created in the namespace.
              - secretName: mon-cert
                hosts:
                  - mon{{ .Values.kl_domain }}

        loki-stack:
          promtail:
            enabled: true
            {{- if ne .Values.provider "gcp" }}
            resources:
              limits:
                cpu: 200m
                memory: 128Mi
              requests:
                cpu: 100m
                memory: 128Mi
            # -- not sure why on the document and code of promtail, it uses `containerSecurityContext` to  override the default values
            # -- https://github.com/grafana/helm-charts/blame/main/charts/promtail/README.md#L77
            # -- https://github.com/grafana/helm-charts/blame/main/charts/promtail/README.md#L109
            # -- https://github.com/grafana/helm-charts/blob/main/charts/promtail/templates/daemonset.yaml#L95
            # -- however, `containerSecurityContext` doesn't work, while `securityContext` can.                                        
            securityContext:
              runAsUser: 0
              runAsGroup: 0
              readOnlyRootFilesystem: false
              privileged: true
            {{- end }}

{{- if eq .Values.provider "gcp" }}
  - name: kidsloop-servicemonitor
    namespace: okc  # Must be in same namespace as KL deployment
    chart: ../charts/kidsloop-servicemonitor
    version: ~0.1.0
    condition: helm_kube_monitoring.enabled
    values:
      - prometheus-mysql-exporter:
          enabled: true
          # https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus-mysql-exporter/values.yaml
          # mysql connection params which build the DATA_SOURCE_NAME env var of the docker container
          mysql:
            db: "{{ .Values.mysql_database }}"
            host: "{{ .Values.mysql_proxy_ip}}"  # "{{ .Values.mysql_host }}"  # {{ .Values.mysql_proxy_ip}} ?
            param: "parseTime=true&charset=utf8mb4"
            pass: "password"
            port: 3306
            # protocol: ""
            user: "{{ .Values.mysql_username }}"
            # secret with full DATA_SOURCE_NAME env var as stringdata
            # existingSecret: ""
            # secret only containing the password
            existingPasswordSecret:
              name: mysql
              key: mysql-password

        prometheus-postgres-exporter:
          enabled: true
          # https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus-postgres-exporter/values.yaml
          prometheusRule:
            enabled: true
            additionalLabels: {}
            namespace: "okc"
            rules:
              # Need to go into observability.yaml because of url...
              - alert: PSQLConnectUsedHighPct
                expr: sum(pg_stat_activity_count) / min(pg_settings_max_connections) > 0.8
                for: 1s
                labels:
                  severity: critical
                annotations:
                  description: Over 80% of available connections are in use
                  summary: Over 80% of available connections are in use
                  dashboard: https://mon{{ .Values.kl_domain }}/grafana/d/postgres/postgresql?orgId=1&refresh=5s
                  runbook_url: https://help.compose.com/docs/postgresql-connection-limits

              - alert: PSQLConnectUsedHighWatermark
                expr: min(pg_settings_max_connections) - sum(pg_stat_activity_count) < 5
                for: 1s
                labels:
                  severity: critical
                annotations:
                  description: There are less than 5 connection slots available in postgres
                  summary: There are less than 5 connection slots available in postgres
                  dashboard: https://mon{{ .Values.kl_domain }}/grafana/d/postgres/postgresql?orgId=1&refresh=5s
                  runbook_url: https://help.compose.com/docs/postgresql-connection-limits

          config:
            datasource:
              # Specify one of both datasource or datasourceSecret
              {{- if eq .Values.provider "gcp" }}
              host: "127.0.0.1"
              {{- else }}
              host: {{ .Values.postgresql_host }}
              {{- end }}
              user: {{ .Values.postgresql_username }}
              # Only one of password and passwordSecret can be specified
              # password: 
              # Specify passwordSecret if DB password is stored in secret.
              passwordSecret:
                # Secret name
                name: postgresql
                # Password key inside secret
                key: postgresql-password
              port: "5432"
              database: '{{ .Values.postgresql_database }}'
              sslmode: disable
            datasourceSecret: {}
              # Specifies if datasource should be sourced from secret value in format: postgresql://login:password@hostname:port/dbname?sslmode=disable
              # Multiple Postgres databases can be configured by comma separated postgres connection strings
              # Secret name
              #  name:
              # Connection string key inside secret
              #  key:
          # mysql connection params which build the DATA_SOURCE_NAME env var of the docker container
          {{- if eq .Values.provider "gcp" }}
          extraContainers:
          - name: cloud-sql-proxy
            image: gcr.io/cloudsql-docker/gce-proxy:1.19.1
            command:
              - "/cloud_sql_proxy"
              - "-ip_address_types=PRIVATE"
              - "-instances={{ .Values.terraform_project }}:{{ .Values.terraform_region }}:{{ .Values.postgresql_database }}=tcp:5432"
            securityContext:
              runAsNonRoot: true
          serviceAccount:
            # Specifies whether a ServiceAccount should be created
            create: false
            # The name of the ServiceAccount to use.
            # If not set and create is true, a name is generated using the fullname template
            name: cloudsql-proxy
            # Add annotations to the ServiceAccount, useful for EKS IAM Roles for Service Accounts or Google Workload Identity.
          {{- end }}

        prometheus-redis-exporter:
          enabled: true
          # https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus-redis-exporter/values.yaml
          redisAddress: redis://{{ .Values.redis_host }}:6379
          auth:
            enabled: false
            # Use existing secret (ignores redisPassword)
            secret:
              name: ""
              key: ""
            # Redis password (when not stored in a secret)
            redisPassword: ""

          serviceMonitor:
            labels:
              # instance: redis://{{ .Values.redis_host }}:6379
              dashboard_host: mon{{ .Values.kl_domain }}
{{- end }}